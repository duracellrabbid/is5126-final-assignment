{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "554f4141",
   "metadata": {},
   "source": [
    "# Dataset links:\n",
    "1. https://www.kaggle.com/datasets/pavansubhasht/ibm-hr-analytics-attrition-dataset\n",
    "2. https://www.kaggle.com/datasets/stealthtechnologies/employee-attrition-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167f653a",
   "metadata": {},
   "source": [
    "# Discussions\n",
    "\n",
    "1. How do we use Gen-AI in this project? (Code plugin) - Done by Xiwen & Aaron\n",
    "\t- RAG (broadbased recommendation?)\n",
    "\t\t- Scrape or get the best practices from top companies\n",
    "\t\t- Use the information to form the knowledge base for the LLM\n",
    "\t\t- Use the LLM to perform broadbased recommendation based on the parameters of the group of employees. \n",
    "2. EDA & Features - Done by Shenghao\n",
    "\t- Feature selection  (Domain knowledge)\n",
    "\t- Dimension reduction? - Done by\n",
    "3. Classification / NN-DL - Done by Jia Hong & Kelda\n",
    "\t- Train a few ensemble models and stack the best 2-3? \n",
    "\t- Hyper-param tuning \n",
    "\t- NN / DL: Are we gonna use supervised learning or NN/DL\n",
    "4. Deployment - Done by Alexander\n",
    "\t- Streamlit\n",
    "\t- FastAPI\n",
    "5. Report structre - Done by Kelda\n",
    "6. Presentation structure - Done by Jia Hong\n",
    "7. Report + Presentation content - By Everyone\n",
    "\n",
    "\n",
    "# Tentative deadline: (Main project deadline: 7th November 6.30pm)\n",
    "- Best practices from top companies (Research) : 27 Oct\n",
    "- Feature selection : 27 Oct\n",
    "- Classification : 1 Nov\n",
    "- Gen-AI RAG : 1 Nov\n",
    "- Deployment : 3 Nov\n",
    "- Draft report + presentation : 5 Nov\n",
    "- Report + presentation : 6 Nov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ac60a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install matplotlib seaborn pandas numpy openai scikit-learn fastapi streamlit dotenv pydantic requests\n",
    "%pip install torch torchvision --index-url https://download.pytorch.org/whl/cu130\n",
    "%pip install langchain-core langchain-openai langgraph \n",
    "%pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a6ddf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db0a00b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally\n",
      "Available models: [Model(id='gpt-4o-mini', created=1721172741, object='model', owned_by='system'), Model(id='gpt-4o-mini-realtime-preview', created=1734387380, object='model', owned_by='system'), Model(id='gpt-5-nano', created=1754426384, object='model', owned_by='system'), Model(id='text-embedding-ada-002', created=1671217299, object='model', owned_by='openai-internal')]\n",
      "OpenAI API key is valid.\n"
     ]
    }
   ],
   "source": [
    "# load OpenAI API key\n",
    "\n",
    "\n",
    "OPENAI_API_KEY = ''\n",
    "try:\n",
    "\tfrom google.colab import userdata\n",
    "\tprint(\"Running in Google Colab\")\n",
    "\tOPENAI_API_KEY = userdata.get('OPENAI_API_KEY', '')\n",
    "except ImportError:\n",
    "\timport dotenv\n",
    "\tdotenv.load_dotenv()\n",
    "\tprint(\"Running locally\")\n",
    "\tOPENAI_API_KEY = os.environ.get('OPENAI_API_KEY', '')\n",
    "\n",
    "openai = OpenAI(api_key=OPENAI_API_KEY)\n",
    "try:\n",
    "\tresponse = openai.models.list()\n",
    "\tprint(\"Available models:\", response.data)\n",
    "\tprint(\"OpenAI API key is valid.\")\n",
    "except Exception as e:\n",
    "\tprint(\"Error with OpenAI API key:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3393965b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Age",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Attrition",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "BusinessTravel",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "DailyRate",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Department",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "DistanceFromHome",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Education",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "EducationField",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "EmployeeCount",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "EmployeeNumber",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "EnvironmentSatisfaction",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Gender",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "HourlyRate",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "JobInvolvement",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "JobLevel",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "JobRole",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "JobSatisfaction",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "MaritalStatus",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "MonthlyIncome",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "MonthlyRate",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "NumCompaniesWorked",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Over18",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "OverTime",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "PercentSalaryHike",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "PerformanceRating",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "RelationshipSatisfaction",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "StandardHours",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "StockOptionLevel",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "TotalWorkingYears",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "TrainingTimesLastYear",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "WorkLifeBalance",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "YearsAtCompany",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "YearsInCurrentRole",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "YearsSinceLastPromotion",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "YearsWithCurrManager",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "2f397f3a-f7d3-4f97-8224-a2b2ebb2f152",
       "rows": [
        [
         "0",
         "41",
         "Yes",
         "Travel_Rarely",
         "1102",
         "Sales",
         "1",
         "2",
         "Life Sciences",
         "1",
         "1",
         "2",
         "Female",
         "94",
         "3",
         "2",
         "Sales Executive",
         "4",
         "Single",
         "5993",
         "19479",
         "8",
         "Y",
         "Yes",
         "11",
         "3",
         "1",
         "80",
         "0",
         "8",
         "0",
         "1",
         "6",
         "4",
         "0",
         "5"
        ],
        [
         "1",
         "49",
         "No",
         "Travel_Frequently",
         "279",
         "Research & Development",
         "8",
         "1",
         "Life Sciences",
         "1",
         "2",
         "3",
         "Male",
         "61",
         "2",
         "2",
         "Research Scientist",
         "2",
         "Married",
         "5130",
         "24907",
         "1",
         "Y",
         "No",
         "23",
         "4",
         "4",
         "80",
         "1",
         "10",
         "3",
         "3",
         "10",
         "7",
         "1",
         "7"
        ],
        [
         "2",
         "37",
         "Yes",
         "Travel_Rarely",
         "1373",
         "Research & Development",
         "2",
         "2",
         "Other",
         "1",
         "4",
         "4",
         "Male",
         "92",
         "2",
         "1",
         "Laboratory Technician",
         "3",
         "Single",
         "2090",
         "2396",
         "6",
         "Y",
         "Yes",
         "15",
         "3",
         "2",
         "80",
         "0",
         "7",
         "3",
         "3",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "3",
         "33",
         "No",
         "Travel_Frequently",
         "1392",
         "Research & Development",
         "3",
         "4",
         "Life Sciences",
         "1",
         "5",
         "4",
         "Female",
         "56",
         "3",
         "1",
         "Research Scientist",
         "3",
         "Married",
         "2909",
         "23159",
         "1",
         "Y",
         "Yes",
         "11",
         "3",
         "3",
         "80",
         "0",
         "8",
         "3",
         "3",
         "8",
         "7",
         "3",
         "0"
        ],
        [
         "4",
         "27",
         "No",
         "Travel_Rarely",
         "591",
         "Research & Development",
         "2",
         "1",
         "Medical",
         "1",
         "7",
         "1",
         "Male",
         "40",
         "3",
         "1",
         "Laboratory Technician",
         "2",
         "Married",
         "3468",
         "16632",
         "9",
         "Y",
         "No",
         "12",
         "3",
         "4",
         "80",
         "1",
         "6",
         "3",
         "3",
         "2",
         "2",
         "2",
         "2"
        ],
        [
         "5",
         "32",
         "No",
         "Travel_Frequently",
         "1005",
         "Research & Development",
         "2",
         "2",
         "Life Sciences",
         "1",
         "8",
         "4",
         "Male",
         "79",
         "3",
         "1",
         "Laboratory Technician",
         "4",
         "Single",
         "3068",
         "11864",
         "0",
         "Y",
         "No",
         "13",
         "3",
         "3",
         "80",
         "0",
         "8",
         "2",
         "2",
         "7",
         "7",
         "3",
         "6"
        ],
        [
         "6",
         "59",
         "No",
         "Travel_Rarely",
         "1324",
         "Research & Development",
         "3",
         "3",
         "Medical",
         "1",
         "10",
         "3",
         "Female",
         "81",
         "4",
         "1",
         "Laboratory Technician",
         "1",
         "Married",
         "2670",
         "9964",
         "4",
         "Y",
         "Yes",
         "20",
         "4",
         "1",
         "80",
         "3",
         "12",
         "3",
         "2",
         "1",
         "0",
         "0",
         "0"
        ],
        [
         "7",
         "30",
         "No",
         "Travel_Rarely",
         "1358",
         "Research & Development",
         "24",
         "1",
         "Life Sciences",
         "1",
         "11",
         "4",
         "Male",
         "67",
         "3",
         "1",
         "Laboratory Technician",
         "3",
         "Divorced",
         "2693",
         "13335",
         "1",
         "Y",
         "No",
         "22",
         "4",
         "2",
         "80",
         "1",
         "1",
         "2",
         "3",
         "1",
         "0",
         "0",
         "0"
        ],
        [
         "8",
         "38",
         "No",
         "Travel_Frequently",
         "216",
         "Research & Development",
         "23",
         "3",
         "Life Sciences",
         "1",
         "12",
         "4",
         "Male",
         "44",
         "2",
         "3",
         "Manufacturing Director",
         "3",
         "Single",
         "9526",
         "8787",
         "0",
         "Y",
         "No",
         "21",
         "4",
         "2",
         "80",
         "0",
         "10",
         "2",
         "3",
         "9",
         "7",
         "1",
         "8"
        ],
        [
         "9",
         "36",
         "No",
         "Travel_Rarely",
         "1299",
         "Research & Development",
         "27",
         "3",
         "Medical",
         "1",
         "13",
         "3",
         "Male",
         "94",
         "3",
         "2",
         "Healthcare Representative",
         "3",
         "Married",
         "5237",
         "16577",
         "6",
         "Y",
         "No",
         "13",
         "3",
         "2",
         "80",
         "2",
         "17",
         "3",
         "2",
         "7",
         "7",
         "7",
         "7"
        ]
       ],
       "shape": {
        "columns": 35,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>BusinessTravel</th>\n",
       "      <th>DailyRate</th>\n",
       "      <th>Department</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>EmployeeCount</th>\n",
       "      <th>EmployeeNumber</th>\n",
       "      <th>...</th>\n",
       "      <th>RelationshipSatisfaction</th>\n",
       "      <th>StandardHours</th>\n",
       "      <th>StockOptionLevel</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1102</td>\n",
       "      <td>Sales</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>279</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1373</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>1392</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>591</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Medical</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>32</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>1005</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>59</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1324</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Medical</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1358</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>38</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>216</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>36</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1299</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>Medical</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Attrition     BusinessTravel  DailyRate              Department  \\\n",
       "0   41       Yes      Travel_Rarely       1102                   Sales   \n",
       "1   49        No  Travel_Frequently        279  Research & Development   \n",
       "2   37       Yes      Travel_Rarely       1373  Research & Development   \n",
       "3   33        No  Travel_Frequently       1392  Research & Development   \n",
       "4   27        No      Travel_Rarely        591  Research & Development   \n",
       "5   32        No  Travel_Frequently       1005  Research & Development   \n",
       "6   59        No      Travel_Rarely       1324  Research & Development   \n",
       "7   30        No      Travel_Rarely       1358  Research & Development   \n",
       "8   38        No  Travel_Frequently        216  Research & Development   \n",
       "9   36        No      Travel_Rarely       1299  Research & Development   \n",
       "\n",
       "   DistanceFromHome  Education EducationField  EmployeeCount  EmployeeNumber  \\\n",
       "0                 1          2  Life Sciences              1               1   \n",
       "1                 8          1  Life Sciences              1               2   \n",
       "2                 2          2          Other              1               4   \n",
       "3                 3          4  Life Sciences              1               5   \n",
       "4                 2          1        Medical              1               7   \n",
       "5                 2          2  Life Sciences              1               8   \n",
       "6                 3          3        Medical              1              10   \n",
       "7                24          1  Life Sciences              1              11   \n",
       "8                23          3  Life Sciences              1              12   \n",
       "9                27          3        Medical              1              13   \n",
       "\n",
       "   ...  RelationshipSatisfaction StandardHours  StockOptionLevel  \\\n",
       "0  ...                         1            80                 0   \n",
       "1  ...                         4            80                 1   \n",
       "2  ...                         2            80                 0   \n",
       "3  ...                         3            80                 0   \n",
       "4  ...                         4            80                 1   \n",
       "5  ...                         3            80                 0   \n",
       "6  ...                         1            80                 3   \n",
       "7  ...                         2            80                 1   \n",
       "8  ...                         2            80                 0   \n",
       "9  ...                         2            80                 2   \n",
       "\n",
       "   TotalWorkingYears  TrainingTimesLastYear WorkLifeBalance  YearsAtCompany  \\\n",
       "0                  8                      0               1               6   \n",
       "1                 10                      3               3              10   \n",
       "2                  7                      3               3               0   \n",
       "3                  8                      3               3               8   \n",
       "4                  6                      3               3               2   \n",
       "5                  8                      2               2               7   \n",
       "6                 12                      3               2               1   \n",
       "7                  1                      2               3               1   \n",
       "8                 10                      2               3               9   \n",
       "9                 17                      3               2               7   \n",
       "\n",
       "  YearsInCurrentRole  YearsSinceLastPromotion  YearsWithCurrManager  \n",
       "0                  4                        0                     5  \n",
       "1                  7                        1                     7  \n",
       "2                  0                        0                     0  \n",
       "3                  7                        3                     0  \n",
       "4                  2                        2                     2  \n",
       "5                  7                        3                     6  \n",
       "6                  0                        0                     0  \n",
       "7                  0                        0                     0  \n",
       "8                  7                        1                     8  \n",
       "9                  7                        7                     7  \n",
       "\n",
       "[10 rows x 35 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('WA_Fn-UseC_-HR-Employee-Attrition.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15745c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240445a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7c9485",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51daf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert 'Attrition' to binary classes: Yes=1, No=0\n",
    "df[\"Attrition_Binary\"] = df[\"Attrition\"].apply(lambda x: 1 if x == \"Yes\" else 0)\n",
    "\n",
    "# Convert 'MaritalStatus' to numerical classes: Married=1, Single=0, Divorced=2\n",
    "df[\"Marital_Status_Class\"] = df[\"MaritalStatus\"].apply(lambda x: 1 if x == \"Married\" else (0 if x == \"Single\" else 2))\n",
    "\n",
    "# Convert 'Gender' to binary classes: Male=1, Female=0\n",
    "df[\"Gender_Binary\"] = df[\"Gender\"].apply(lambda x: 1 if x == \"Male\" else 0)\n",
    "\n",
    "\n",
    "# convert 'OverTime' to binary classes: Yes=1, No=0\n",
    "df[\"OverTime_Binary\"] = df[\"OverTime\"].apply(lambda x: 1 if x == \"Yes\" else 0)\n",
    "\n",
    "# convert 'BusinessTravel' to numerical classes: Non-Travel=0, Travel_Rarely=1, Travel_Frequently=2\n",
    "df[\"Business_Travel_Class\"] = df[\"BusinessTravel\"].apply(lambda x: 0 if x == \"Non-Travel\" else (1 if x == \"Travel_Rarely\" else 2))\n",
    "\n",
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66454d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['Attrition_Binary'].value_counts().plot(kind='bar')\n",
    "plt.title('Attrition Distribution')\n",
    "plt.show()\n",
    "\n",
    "# TODO : Plot a pie chart for Marital Status distribution\n",
    "df['Marital_Status_Class'].value_counts().plot(kind='pie', autopct='%1.1f%%')\n",
    "plt.title('Marital Status Distribution')\n",
    "plt.show()\n",
    "\n",
    "# TODO : Plot a histogram for Age distribution\n",
    "df['Age'].plot(kind='hist', bins=10)\n",
    "plt.title('Age Distribution')\n",
    "plt.xlabel('Age')\n",
    "plt.show()\n",
    "\n",
    "# Correlation heatmap for numerical features\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(12,10))\n",
    "correlation_matrix = df[df.select_dtypes(include=[np.number]).columns].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d56280",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9897e6",
   "metadata": {},
   "source": [
    "# Experiment with Gen-AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac8e024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use OpenAI API to generate insights from the dataset\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "system_prompt = \"\"\"You are a data analyst. Given the summary statistics of a dataset, provide insights about the data.\"\"\"\n",
    "user_prompt = f\"\"\"Here are the summary statistics of the dataset:\n",
    "{df.describe().to_string()}\n",
    "Provide insights about the data.\"\"\"\n",
    "response = openai.chat.completions.create(\n",
    "\tmodel=\"gpt-4o-mini\",\n",
    "\tmessages=[\n",
    "\t\t{\"role\": \"system\", \"content\": system_prompt},\n",
    "\t\t{\"role\": \"user\", \"content\": user_prompt}\n",
    "\t]\n",
    ")\n",
    "print(\"AI-generated insights:\")\n",
    "display(Markdown(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b947bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: To use OpenAI for feature selection or engineering and return the results as a list\n",
    "\n",
    "class FeatureSuggestions(BaseModel):\n",
    "    important_features: list[str]\n",
    "    reasoning: str\n",
    "\n",
    "system_prompt_fs = \"\"\"You are a feature engineering expert.\n",
    "Return your answer as a JSON object like this:\n",
    "{\n",
    "  \"important_features\": [\"feature1\", \"feature2\"],\n",
    "  \"reasoning\": \"short explanation\"\n",
    "}\"\"\"\n",
    "user_prompt_fs = f\"\"\"Here are the summary statistics of the dataset:\n",
    "{df.describe().to_string()}\n",
    "Suggest the top 10 most important features for predicting employee attrition.\"\"\"\n",
    "response_fs = openai.chat.completions.create(\n",
    "\tmodel=\"gpt-4o-mini\",\n",
    " \tresponse_format={\"type\": \"json_object\"},\n",
    "\ttemperature=0.5,\n",
    "\tmessages=[\n",
    "\t\t{\"role\": \"system\", \"content\": system_prompt_fs},\n",
    "\t\t{\"role\": \"user\", \"content\": user_prompt_fs}\n",
    "\t]\n",
    ")\n",
    "response_json = response_fs.choices[0].message.content\n",
    "parsed = FeatureSuggestions.model_validate_json(response_json)\n",
    "\n",
    "# 5️⃣ Use safely\n",
    "print(parsed.model_dump_json(indent=2))\n",
    "print(\"Important features:\", parsed.important_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2aca50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use Openai API to perform EDA, will need to perform function calling\n",
    "\n",
    "import json\n",
    "\n",
    "\n",
    "# Define functions that the AI can call\n",
    "def check_missing_data(df_name=\"df\"):\n",
    "    \"\"\"Check for missing data in the dataset\"\"\"\n",
    "    missing = df.isna().sum()\n",
    "    missing_pct = (df.isna().sum() / len(df)) * 100\n",
    "    result = pd.DataFrame({\n",
    "        'Missing_Count': missing,\n",
    "        'Missing_Percentage': missing_pct\n",
    "    })\n",
    "    result = result[result['Missing_Count'] > 0]\n",
    "    \n",
    "    if len(result) == 0:\n",
    "        return \"No missing data found in the dataset.\"\n",
    "    else:\n",
    "        return f\"Missing data summary:\\n{result.to_string()}\"\n",
    "\n",
    "def plot_visualization(plot_type, column_name, title=None, bins=20):\n",
    "    \"\"\"Create a visualization for the specified column\"\"\"\n",
    "    try:\n",
    "        if plot_type == \"histogram\":\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            df[column_name].plot(kind='hist', bins=bins, edgecolor='black')\n",
    "            plt.title(title or f'Histogram of {column_name}')\n",
    "            plt.xlabel(column_name)\n",
    "            plt.ylabel('Frequency')\n",
    "            plt.grid(axis='y', alpha=0.3)\n",
    "            plt.show()\n",
    "            return f\"Created histogram for {column_name}\"\n",
    "            \n",
    "        elif plot_type == \"bar\":\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            df[column_name].value_counts().plot(kind='bar', edgecolor='black')\n",
    "            plt.title(title or f'Bar Chart of {column_name}')\n",
    "            plt.xlabel(column_name)\n",
    "            plt.ylabel('Count')\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.grid(axis='y', alpha=0.3)\n",
    "            plt.show()\n",
    "            return f\"Created bar chart for {column_name}\"\n",
    "            \n",
    "        elif plot_type == \"pie\":\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            df[column_name].value_counts().plot(kind='pie', autopct='%1.1f%%')\n",
    "            plt.title(title or f'Pie Chart of {column_name}')\n",
    "            plt.ylabel('')\n",
    "            plt.show()\n",
    "            return f\"Created pie chart for {column_name}\"\n",
    "            \n",
    "        elif plot_type == \"box\":\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            df.boxplot(column=column_name)\n",
    "            plt.title(title or f'Box Plot of {column_name}')\n",
    "            plt.ylabel(column_name)\n",
    "            plt.grid(axis='y', alpha=0.3)\n",
    "            plt.show()\n",
    "            return f\"Created box plot for {column_name}\"\n",
    "            \n",
    "        elif plot_type == \"scatter\":\n",
    "            # For scatter, column_name should be \"column1,column2\"\n",
    "            cols = column_name.split(',')\n",
    "            if len(cols) == 2:\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                plt.scatter(df[cols[0]], df[cols[1]], alpha=0.5)\n",
    "                plt.xlabel(cols[0])\n",
    "                plt.ylabel(cols[1])\n",
    "                plt.title(title or f'Scatter Plot: {cols[0]} vs {cols[1]}')\n",
    "                plt.grid(alpha=0.3)\n",
    "                plt.show()\n",
    "                return f\"Created scatter plot for {cols[0]} vs {cols[1]}\"\n",
    "            else:\n",
    "                return \"Error: Scatter plot requires two columns separated by comma\"\n",
    "        else:\n",
    "            return f\"Error: Unknown plot type '{plot_type}'\"\n",
    "    except Exception as e:\n",
    "        return f\"Error creating {plot_type} for {column_name}: {str(e)}\"\n",
    "\n",
    "def encode_categorical_column(column_name):\n",
    "    \"\"\"\n",
    "    Encode a categorical column to numerical values\n",
    "    mapping_dict should be like: {\"Yes\": 1, \"No\": 0}\n",
    "    \"\"\"\n",
    "    try:\n",
    "        mapping_dict = {val: idx for idx, val in enumerate(df[column_name].unique())}\n",
    "            \n",
    "        new_column_name = f\"{column_name}_Encoded\"\n",
    "        df[new_column_name] = df[column_name].map(mapping_dict)\n",
    "        \n",
    "        # Check if any values were not mapped\n",
    "        unmapped = df[df[new_column_name].isna()][column_name].unique()\n",
    "        if len(unmapped) > 0:\n",
    "            return f\"Warning: Column '{column_name}' encoded to '{new_column_name}', but values {unmapped.tolist()} were not in mapping\"\n",
    "        \n",
    "        return f\"Successfully encoded '{column_name}' to '{new_column_name}' with mapping: {mapping_dict}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error encoding {column_name}: {str(e)}\"\n",
    "\n",
    "def get_column_info(column_name=None):\n",
    "    \"\"\"Get information about columns in the dataset\"\"\"\n",
    "    if column_name:\n",
    "        if column_name in df.columns:\n",
    "            unique_vals = df[column_name].unique()\n",
    "            return f\"Column '{column_name}':\\n- Type: {df[column_name].dtype}\\n- Unique values ({len(unique_vals)}): {unique_vals.tolist()[:20]}\\n- Sample data: {df[column_name].head(5).tolist()}\"\n",
    "        else:\n",
    "            return f\"Column '{column_name}' not found in dataset\"\n",
    "    else:\n",
    "        return f\"Available columns:\\n{df.columns.tolist()}\\n\\nData types:\\n{df.dtypes.to_string()}\"\n",
    "\n",
    "# Define function schemas for OpenAI\n",
    "functions = [\n",
    "    {\n",
    "        \"name\": \"check_missing_data\",\n",
    "        \"description\": \"Check for missing data in the dataset and return a summary\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"df_name\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Name of the dataframe (default: 'df')\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"plot_visualization\",\n",
    "        \"description\": \"Create a visualization (histogram, bar, pie, box, or scatter plot) for a specified column\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"plot_type\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"histogram\", \"bar\", \"pie\", \"box\", \"scatter\"],\n",
    "                    \"description\": \"Type of plot to create\"\n",
    "                },\n",
    "                \"column_name\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Name of the column to plot. For scatter plots, use 'column1,column2' format\"\n",
    "                },\n",
    "                \"title\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Optional title for the plot\"\n",
    "                },\n",
    "                \"bins\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\": \"Number of bins for histogram (default: 20)\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"plot_type\", \"column_name\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"encode_categorical_column\",\n",
    "        \"description\": \"Encode a categorical column to numerical values using a provided mapping dictionary\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"column_name\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Name of the column to encode\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"column_name\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"get_column_info\",\n",
    "        \"description\": \"Get information about columns in the dataset, including data types and unique values\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"column_name\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Name of specific column to inspect. If not provided, returns info about all columns\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Map function names to actual functions\n",
    "available_functions = {\n",
    "    \"check_missing_data\": check_missing_data,\n",
    "    \"plot_visualization\": plot_visualization,\n",
    "    \"encode_categorical_column\": encode_categorical_column,\n",
    "    \"get_column_info\": get_column_info\n",
    "}\n",
    "\n",
    "print(\"✅ EDA functions and schemas defined successfully!\")\n",
    "print(f\"Available functions: {list(available_functions.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014a18b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute OpenAI-powered EDA with function calling\n",
    "\n",
    "# Create the initial prompt\n",
    "system_prompt_eda = \"\"\"You are a data analyst assistant. You have access to functions to perform EDA on an employee attrition dataset.\n",
    "\n",
    "Your task is to:\n",
    "1. Check for missing data in the dataset\n",
    "2. Create at least 4 different visualizations to explore the data (choose appropriate plot types for different columns)\n",
    "3. Identify and encode categorical columns that need to be converted to numerical values for machine learning\n",
    "\n",
    "Use the available functions to accomplish these tasks. Call get_column_info first to understand the dataset structure.\"\"\"\n",
    "\n",
    "user_prompt_eda = \"\"\"Please perform comprehensive EDA on the employee attrition dataset. \n",
    "First, check what columns are available, then check for missing data, create insightful visualizations, \n",
    "and finally encode any remaining categorical columns that haven't been encoded yet.\"\"\"\n",
    "\n",
    "# Initialize conversation\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt_eda},\n",
    "    {\"role\": \"user\", \"content\": user_prompt_eda}\n",
    "]\n",
    "\n",
    "print(\"🤖 Starting AI-powered EDA with function calling...\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Run the conversation loop\n",
    "max_iterations = 15  # Prevent infinite loops\n",
    "iteration = 0\n",
    "\n",
    "while iteration < max_iterations:\n",
    "    iteration += 1\n",
    "    print(f\"\\n--- Iteration {iteration} ---\")\n",
    "    \n",
    "    # Make API call\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        tools=[{\"type\": \"function\", \"function\": func} for func in functions],\n",
    "        tool_choice=\"auto\"\n",
    "    )\n",
    "    \n",
    "    response_message = response.choices[0].message\n",
    "    messages.append(response_message)\n",
    "    \n",
    "    # Check if the model wants to call functions\n",
    "    tool_calls = response_message.tool_calls\n",
    "    \n",
    "    if not tool_calls:\n",
    "        # No more function calls - the assistant has finished\n",
    "        print(\"\\n✅ AI Assistant finished:\")\n",
    "        print(response_message.content)\n",
    "        break\n",
    "    \n",
    "    # Process each function call\n",
    "    for tool_call in tool_calls:\n",
    "        function_name = tool_call.function.name\n",
    "        function_args = json.loads(tool_call.function.arguments)\n",
    "        \n",
    "        print(f\"\\n🔧 Calling function: {function_name}\")\n",
    "        print(f\"   Arguments: {function_args}\")\n",
    "        \n",
    "        # Call the actual function\n",
    "        function_to_call = available_functions[function_name]\n",
    "        function_response = function_to_call(**function_args)\n",
    "        \n",
    "        print(f\"   Result: {function_response[:200]}...\" if len(str(function_response)) > 200 else f\"   Result: {function_response}\")\n",
    "        \n",
    "        # Add function response to messages\n",
    "        messages.append({\n",
    "            \"role\": \"tool\",\n",
    "            \"tool_call_id\": tool_call.id,\n",
    "            \"name\": function_name,\n",
    "            \"content\": str(function_response)\n",
    "        })\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"✅ EDA completed!\")\n",
    "print(f\"\\nTotal iterations: {iteration}\")\n",
    "print(f\"Check the visualizations above and the new encoded columns in the dataframe.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7686abe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the updated dataframe with newly encoded columns\n",
    "print(\"\\n📊 Updated DataFrame Info:\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"\\nFirst few rows with all columns (including newly encoded):\")\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546b1ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use OpenAI API to suggest Machine Learning models based on the dataset and suggest starting parameters\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional\n",
    "\n",
    "class ModelSuggestion(BaseModel):\n",
    "\tmodel_name: str = Field(description=\"Name of the suggested machine learning model\")\n",
    "\tparameters: dict = Field(description=\"Suggested starting parameters for the model\")\n",
    "\treasoning: str = Field(description=\"Reasoning behind the model choice and parameters\")\n",
    "\n",
    "model_suggestion_schema = {\n",
    "    \"name\": \"ModelSuggestion\",\n",
    "    \"schema\": ModelSuggestion.model_json_schema()\n",
    "}\n",
    "\n",
    "system_prompt_ml = \"\"\"You are a machine learning expert. Based on the dataset provided, suggest an appropriate machine learning model for predicting employee attrition along with starting parameters.\n",
    "Return your answer based on the following JSON schema:\n",
    "{\n",
    "  \"model_name\": \"string\",\n",
    "  \"parameters\": {\"type\": \"object\"},\n",
    "  \"reasoning\": \"string\"\n",
    "}\"\"\"\n",
    "\n",
    "user_prompt_ml = f\"\"\"Here are the summary statistics of the dataset:\n",
    "{df.describe().to_string()}\n",
    "Suggest an appropriate machine learning model for predicting employee attrition along with starting parameters.\"\"\"\n",
    "response_ml = openai.chat.completions.create(\n",
    "\tmodel=\"gpt-4o-mini\",\n",
    " \tresponse_format={\"type\": \"json_schema\", \"json_schema\": model_suggestion_schema},\n",
    "\ttemperature=0.5,\n",
    "\tmessages=[\n",
    "\t\t{\"role\": \"system\", \"content\": system_prompt_ml},\n",
    "\t\t{\"role\": \"user\", \"content\": user_prompt_ml}\n",
    "\t]\n",
    ")\n",
    "response_json_ml = response_ml.choices[0].message.content\n",
    "parsed_ml = ModelSuggestion.model_validate_json(response_json_ml)\n",
    "\n",
    "print(\"✅ Machine Learning Model Suggestion:\")\n",
    "print(parsed_ml.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7957b69a",
   "metadata": {},
   "source": [
    "# Agentic AI Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a8c0c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8ff1ec9",
   "metadata": {},
   "source": [
    "# 🔁 Multi-Agent EDA with LangChain + LangGraph\n",
    "\n",
    "This section builds a small agentic pipeline that collaborates on EDA for the employee attrition dataset using OpenAI tools:\n",
    "\n",
    "- Data dictionary: generates column descriptions with an LLM (Pydantic-typed)\n",
    "- Missing values: decides mean vs median and imputes (Pydantic-typed)\n",
    "- Visualizations: produces plots based on the dictionary\n",
    "- Encoding: recommends and applies encodings for non-numeric columns (LLM-guided, Pydantic-typed)\n",
    "- Insights: generates human-readable Markdown\n",
    "- Feature selection: suggests whether to use all columns or a subset (Pydantic-typed)\n",
    "\n",
    "You can re-run this section safely; it’s designed to be idempotent for repeated runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ed4b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pydantic models and helpers for the multi-agent EDA\n",
    "from typing import List, Literal, Optional, Dict, Any\n",
    "from pydantic import BaseModel, Field\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1) Data dictionary\n",
    "class DataDictionaryField(BaseModel):\n",
    "    name: str\n",
    "    dtype: str\n",
    "    description: str\n",
    "    is_numeric: bool\n",
    "    unique_values_sample: List[Any] = Field(default_factory=list)\n",
    "\n",
    "class DataDictionary(BaseModel):\n",
    "    dataset_name: str\n",
    "    fields: List[DataDictionaryField]\n",
    "\n",
    "# 2) Missing values decisions\n",
    "ImputeStrategy = Literal[\"mean\", \"median\", \"none\"]\n",
    "\n",
    "class ImputationDecision(BaseModel):\n",
    "    column: str\n",
    "    strategy: ImputeStrategy\n",
    "    reason: str\n",
    "\n",
    "class ImputationPlan(BaseModel):\n",
    "    decisions: List[ImputationDecision]\n",
    "\n",
    "# 4) Encoding decisions\n",
    "EncodingType = Literal[\n",
    "    \"one_hot\",    # small cardinality categorical\n",
    "    \"ordinal\",    # natural order\n",
    "    \"binary\",     # boolean/yes-no\n",
    "    \"target\",     # high-cardinality target encoding (note: here we won’t implement target leakage; for demo use one_hot fallback)\n",
    "    \"none\"\n",
    "]\n",
    "\n",
    "class EncodingDecision(BaseModel):\n",
    "    column: str\n",
    "    encode: bool\n",
    "    encoding_type: EncodingType\n",
    "    reason: str\n",
    "\n",
    "class EncodingPlan(BaseModel):\n",
    "    decisions: List[EncodingDecision]\n",
    "\n",
    "# 6) Feature selection\n",
    "class FeatureSelection(BaseModel):\n",
    "    use_all_columns: bool\n",
    "    selected_columns: List[str]\n",
    "    reason: str\n",
    "\n",
    "# Helpers\n",
    "NUMERIC_DTYPES = (np.number,)\n",
    "\n",
    "\n",
    "def summarize_dataframe(df: pd.DataFrame) -> Dict[str, Any]:\n",
    "    summary = {\n",
    "        \"shape\": df.shape,\n",
    "        \"columns\": [],\n",
    "        \"missing\": df.isna().sum().to_dict(),\n",
    "        \"desc_numeric\": df.select_dtypes(include=[np.number]).describe().to_dict(),\n",
    "        \"dtypes\": df.dtypes.astype(str).to_dict(),\n",
    "    }\n",
    "    for col in df.columns:\n",
    "        col_info = {\n",
    "            \"name\": col,\n",
    "            \"dtype\": str(df[col].dtype),\n",
    "            \"is_numeric\": pd.api.types.is_numeric_dtype(df[col]),\n",
    "            \"n_unique\": int(df[col].nunique(dropna=True)),\n",
    "            \"unique_values_sample\": df[col].dropna().unique().tolist()[:10],\n",
    "        }\n",
    "        summary[\"columns\"].append(col_info)\n",
    "    return summary\n",
    "\n",
    "print(\"✅ Models and helpers ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9438e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangChain + LangGraph setup and LLMs\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser, StrOutputParser\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict\n",
    "import os\n",
    "\n",
    "# Ensure env var is available for LangChain OpenAI\n",
    "if 'OPENAI_API_KEY' in globals() and OPENAI_API_KEY and not os.environ.get('OPENAI_API_KEY'):\n",
    "    os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
    "\n",
    "# Use existing OPENAI_API_KEY from earlier cell; if missing, set via env\n",
    "llm_json = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.2)\n",
    "llm_text = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.2)\n",
    "\n",
    "# Output parsers\n",
    "parser_data_dict = PydanticOutputParser(pydantic_object=DataDictionary)\n",
    "parser_impute = PydanticOutputParser(pydantic_object=ImputationPlan)\n",
    "parser_encode = PydanticOutputParser(pydantic_object=EncodingPlan)\n",
    "parser_features = PydanticOutputParser(pydantic_object=FeatureSelection)\n",
    "\n",
    "# Prompts\n",
    "prompt_data_dict = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a data dictionary generator for an HR attrition dataset. Given column summaries, write concise, practical descriptions for business analysts.\"),\n",
    "    (\"human\", \"Dataset name: {dataset_name}\\n\\nColumns JSON (with dtype, numeric flag, unique samples):\\n{columns_json}\\n\\nReturn a JSON strictly matching this schema:\\n{format_instructions}\")\n",
    "]).partial(format_instructions=parser_data_dict.get_format_instructions())\n",
    "\n",
    "prompt_impute = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You decide imputation for missing values. Use mean for symmetric numeric distributions without strong outliers; use median otherwise. For non-numeric, choose 'none'.\"),\n",
    "    (\"human\", \"Missing summary: {missing_json}\\nNumeric describe: {desc_json}\\nDtypes: {dtypes_json}\\nReturn a JSON plan with one decision per column.\\n{format_instructions}\")\n",
    "]).partial(format_instructions=parser_impute.get_format_instructions())\n",
    "\n",
    "prompt_encode = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an encoding planner. For non-numeric columns, decide whether to encode and how. Use: binary for yes/no; one_hot for low-cardinality categoricals; ordinal only if natural order is evident; none for IDs/unique identifiers. Avoid target encoding here.\"),\n",
    "    (\"human\", \"Dtypes: {dtypes_json}\\nUnique counts: {unique_counts_json}\\nReturn a JSON encoding plan.\\n{format_instructions}\")\n",
    "]).partial(format_instructions=parser_encode.get_format_instructions())\n",
    "\n",
    "prompt_insights = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a senior data analyst. Write crisp, well-structured Markdown insights for stakeholders. Avoid hallucinating unknown business rules.\"),\n",
    "    (\"human\", \"Provide insights based on: shape={shape}, dictionary_fields={fields}, missing={missing_json}, numeric_summary={desc_json}. Include 4-7 bullet points with concrete observations and cautions.\")\n",
    "])\n",
    "\n",
    "prompt_features = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You recommend feature subsets for employee attrition prediction. Avoid leakage (e.g., Attrition label). Prefer columns with predictive signal and reasonable cardinality.\"),\n",
    "    (\"human\", \"Columns and dtypes: {dtypes_json}\\nEncoded columns present: {encoded_cols}\\nBusiness target column: {target}\\nReturn JSON with use_all_columns and selected_columns if not all.\\n{format_instructions}\")\n",
    "]).partial(format_instructions=parser_features.get_format_instructions())\n",
    "\n",
    "print(\"✅ LangChain+LangGraph and prompts initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ae5d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent node functions\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Define a graph state\n",
    "class EDAState(TypedDict, total=False):\n",
    "    df: pd.DataFrame\n",
    "    summary: Dict[str, Any]\n",
    "    data_dictionary: DataDictionary\n",
    "    imputation_plan: ImputationPlan\n",
    "    encoding_plan: EncodingPlan\n",
    "    insights_md: str\n",
    "    feature_selection: FeatureSelection\n",
    "\n",
    "\n",
    "def node_summarize(state: EDAState) -> EDAState:\n",
    "    df_local = state[\"df\"]\n",
    "    state[\"summary\"] = summarize_dataframe(df_local)\n",
    "    return state\n",
    "\n",
    "\n",
    "def node_data_dictionary(state: EDAState) -> EDAState:\n",
    "    summary = state[\"summary\"]\n",
    "    columns_json = json.dumps(summary[\"columns\"], ensure_ascii=False)\n",
    "    chain = prompt_data_dict | llm_json | parser_data_dict\n",
    "    dd = chain.invoke({\n",
    "        \"dataset_name\": \"IBM HR Attrition\",\n",
    "        \"columns_json\": columns_json,\n",
    "    })\n",
    "    state[\"data_dictionary\"] = dd\n",
    "    return state\n",
    "\n",
    "\n",
    "def node_missing_values(state: EDAState) -> EDAState:\n",
    "    df_local = state[\"df\"].copy()\n",
    "    summary = state[\"summary\"]\n",
    "    chain = prompt_impute | llm_json | parser_impute\n",
    "    plan = chain.invoke({\n",
    "        \"missing_json\": json.dumps(summary[\"missing\"], ensure_ascii=False),\n",
    "        \"desc_json\": json.dumps(summary[\"desc_numeric\"], ensure_ascii=False),\n",
    "        \"dtypes_json\": json.dumps(summary[\"dtypes\"], ensure_ascii=False),\n",
    "    })\n",
    "    # Apply imputations\n",
    "    for d in plan.decisions:\n",
    "        col = d.column\n",
    "        if col not in df_local.columns:\n",
    "            continue\n",
    "        if d.strategy == \"mean\" and pd.api.types.is_numeric_dtype(df_local[col]):\n",
    "            df_local[col] = df_local[col].fillna(df_local[col].mean())\n",
    "        elif d.strategy == \"median\" and pd.api.types.is_numeric_dtype(df_local[col]):\n",
    "            df_local[col] = df_local[col].fillna(df_local[col].median())\n",
    "        # 'none' -> no action\n",
    "    state[\"df\"] = df_local\n",
    "    state[\"imputation_plan\"] = plan\n",
    "    return state\n",
    "\n",
    "\n",
    "def node_visualize(state: EDAState) -> EDAState:\n",
    "    df_local = state[\"df\"]\n",
    "    dd = state[\"data_dictionary\"]\n",
    "    # Basic, informative plots chosen based on dictionary\n",
    "    numeric_cols = [f.name for f in dd.fields if f.is_numeric][:6]\n",
    "    cat_cols = [f.name for f in dd.fields if not f.is_numeric][:4]\n",
    "\n",
    "    # Distribution plots for numeric columns\n",
    "    for col in numeric_cols:\n",
    "        try:\n",
    "            plt.figure(figsize=(6,4))\n",
    "            sns.histplot(df_local[col].dropna(), kde=True)\n",
    "            plt.title(f\"Distribution of {col}\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        except Exception as e:\n",
    "            print(f\"[viz] Skipped {col}: {e}\")\n",
    "\n",
    "    # Bar charts for categorical columns\n",
    "    for col in cat_cols:\n",
    "        try:\n",
    "            plt.figure(figsize=(6,4))\n",
    "            df_local[col].value_counts(dropna=False).head(20).plot(kind='bar', edgecolor='black')\n",
    "            plt.title(f\"Value Counts of {col}\")\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        except Exception as e:\n",
    "            print(f\"[viz] Skipped {col}: {e}\")\n",
    "\n",
    "    # Correlation heatmap\n",
    "    try:\n",
    "        plt.figure(figsize=(10,8))\n",
    "        corr = df_local.select_dtypes(include=[np.number]).corr()\n",
    "        sns.heatmap(corr, cmap='coolwarm', center=0)\n",
    "        plt.title('Correlation Heatmap (Numeric)')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"[viz] Heatmap skipped: {e}\")\n",
    "\n",
    "    return state\n",
    "\n",
    "\n",
    "def node_encoding(state: EDAState) -> EDAState:\n",
    "    df_local = state[\"df\"].copy()\n",
    "    summary = summarize_dataframe(df_local)  # refresh after imputation\n",
    "    unique_counts = {c[\"name\"]: c[\"n_unique\"] for c in summary[\"columns\"]}\n",
    "    chain = prompt_encode | llm_json | parser_encode\n",
    "    plan = chain.invoke({\n",
    "        \"dtypes_json\": json.dumps(summary[\"dtypes\"], ensure_ascii=False),\n",
    "        \"unique_counts_json\": json.dumps(unique_counts, ensure_ascii=False),\n",
    "    })\n",
    "\n",
    "    # Apply encoding decisions\n",
    "    for d in plan.decisions:\n",
    "        col = d.column\n",
    "        if col not in df_local.columns:\n",
    "            continue\n",
    "        if d.encoding_type == \"none\" or not d.encode:\n",
    "            continue\n",
    "        if d.encoding_type == \"binary\":\n",
    "            # Map yes/no-like or two-level categories to 0/1\n",
    "            if pd.api.types.is_numeric_dtype(df_local[col]):\n",
    "                continue\n",
    "            levels = df_local[col].dropna().unique()\n",
    "            if len(levels) == 2:\n",
    "                mapping = {levels[0]: 0, levels[1]: 1}\n",
    "                df_local[f\"{col}_bin\"] = df_local[col].map(mapping)\n",
    "        elif d.encoding_type == \"ordinal\":\n",
    "            # Fallback to factorize order unless a natural order is obvious; here we factorize\n",
    "            if not pd.api.types.is_numeric_dtype(df_local[col]):\n",
    "                codes, uniques = pd.factorize(df_local[col])\n",
    "                df_local[f\"{col}_ord\"] = codes\n",
    "        elif d.encoding_type == \"one_hot\":\n",
    "            try:\n",
    "                dummies = pd.get_dummies(df_local[col], prefix=col, dummy_na=False)\n",
    "                # Avoid column explosion for very high cardinality\n",
    "                if dummies.shape[1] <= 30:\n",
    "                    df_local = pd.concat([df_local, dummies], axis=1)\n",
    "                else:\n",
    "                    # fallback to factorize when too many levels\n",
    "                    codes, uniques = pd.factorize(df_local[col])\n",
    "                    df_local[f\"{col}_ord\"] = codes\n",
    "            except Exception as e:\n",
    "                print(f\"[encode] {col} one_hot failed: {e}\")\n",
    "    state[\"df\"] = df_local\n",
    "    state[\"encoding_plan\"] = plan\n",
    "    return state\n",
    "\n",
    "\n",
    "def node_insights(state: EDAState) -> EDAState:\n",
    "    summary = state[\"summary\"]\n",
    "    dd = state.get(\"data_dictionary\")\n",
    "    fields_json = [f.model_dump() for f in (dd.fields if dd else [])]\n",
    "    chain = prompt_insights | llm_text | StrOutputParser()\n",
    "    md = chain.invoke({\n",
    "        \"shape\": str(summary.get(\"shape\")),\n",
    "        \"fields\": json.dumps(fields_json, ensure_ascii=False),\n",
    "        \"missing_json\": json.dumps(summary.get(\"missing\", {}), ensure_ascii=False),\n",
    "        \"desc_json\": json.dumps(summary.get(\"desc_numeric\", {}), ensure_ascii=False),\n",
    "    })\n",
    "    state[\"insights_md\"] = md\n",
    "    return state\n",
    "\n",
    "\n",
    "def node_feature_selection(state: EDAState) -> EDAState:\n",
    "    df_local = state[\"df\"]\n",
    "    dtypes = df_local.dtypes.astype(str).to_dict()\n",
    "    encoded_cols = [c for c in df_local.columns if c.endswith((\"_bin\", \"_ord\")) or \"_\" in c and any(x in c for x in [\"Attrition_Binary\", \"Business_Travel_Class\"]) ]\n",
    "    chain = prompt_features | llm_json | parser_features\n",
    "    fs = chain.invoke({\n",
    "        \"dtypes_json\": json.dumps(dtypes, ensure_ascii=False),\n",
    "        \"encoded_cols\": json.dumps(encoded_cols, ensure_ascii=False),\n",
    "        \"target\": \"Attrition_Binary\",\n",
    "    })\n",
    "    state[\"feature_selection\"] = fs\n",
    "    return state\n",
    "\n",
    "print(\"✅ Agent node functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6841a12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and run the LangGraph pipeline\n",
    "from langgraph.graph import StateGraph\n",
    "\n",
    "# Guard: ensure df exists\n",
    "try:\n",
    "    assert 'df' in globals()\n",
    "except AssertionError:\n",
    "    raise RuntimeError(\"DataFrame 'df' not found. Run earlier cells to load the dataset.\")\n",
    "\n",
    "eda_graph = StateGraph(EDAState)\n",
    "eda_graph.add_node(\"summarize\", node_summarize)\n",
    "eda_graph.add_node(\"data_dictionary\", node_data_dictionary)\n",
    "eda_graph.add_node(\"missing_values\", node_missing_values)\n",
    "eda_graph.add_node(\"visualize\", node_visualize)\n",
    "eda_graph.add_node(\"encoding\", node_encoding)\n",
    "eda_graph.add_node(\"insights\", node_insights)\n",
    "eda_graph.add_node(\"feature_selection\", node_feature_selection)\n",
    "\n",
    "# Order: summarize -> data_dictionary -> missing -> visualize -> encoding -> insights -> feature_selection\n",
    "eda_graph.add_edge(\"summarize\", \"data_dictionary\")\n",
    "eda_graph.add_edge(\"data_dictionary\", \"missing_values\")\n",
    "eda_graph.add_edge(\"missing_values\", \"visualize\")\n",
    "eda_graph.add_edge(\"visualize\", \"encoding\")\n",
    "eda_graph.add_edge(\"encoding\", \"insights\")\n",
    "eda_graph.add_edge(\"insights\", \"feature_selection\")\n",
    "eda_graph.add_edge(\"feature_selection\", END)\n",
    "eda_graph.set_entry_point(\"summarize\")\n",
    "\n",
    "compiled = eda_graph.compile()\n",
    "\n",
    "initial_state: EDAState = {\"df\": df.copy()}\n",
    "result_state = compiled.invoke(initial_state)\n",
    "\n",
    "# Store to variables for easy access\n",
    "eda_state = result_state\n",
    "print(\"✅ EDA graph executed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f024e5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results from the multi-agent EDA\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "if 'eda_state' not in globals():\n",
    "    raise RuntimeError(\"EDA state not found. Run the graph execution cell first.\")\n",
    "\n",
    "# 1) Data dictionary\n",
    "print(\"\\n📘 Data Dictionary (first 20 fields):\")\n",
    "if eda_state.get(\"data_dictionary\"):\n",
    "    dd_df = pd.DataFrame([f.model_dump() for f in eda_state[\"data_dictionary\"].fields])\n",
    "    display(dd_df.head(20))\n",
    "else:\n",
    "    print(\"No data dictionary produced.\")\n",
    "\n",
    "# 2) Imputation plan\n",
    "print(\"\\n🧩 Imputation Decisions:\")\n",
    "if eda_state.get(\"imputation_plan\"):\n",
    "    imp_df = pd.DataFrame([d.model_dump() for d in eda_state[\"imputation_plan\"].decisions])\n",
    "    display(imp_df)\n",
    "else:\n",
    "    print(\"No imputation plan produced.\")\n",
    "\n",
    "# 3) Encoding plan\n",
    "print(\"\\n🔡 Encoding Decisions:\")\n",
    "if eda_state.get(\"encoding_plan\"):\n",
    "    enc_df = pd.DataFrame([d.model_dump() for d in eda_state[\"encoding_plan\"].decisions])\n",
    "    display(enc_df)\n",
    "else:\n",
    "    print(\"No encoding plan produced.\")\n",
    "\n",
    "# 4) Insights (Markdown)\n",
    "print(\"\\n🧠 Insights:\")\n",
    "if eda_state.get(\"insights_md\"):\n",
    "    display(Markdown(eda_state[\"insights_md\"]))\n",
    "else:\n",
    "    print(\"No insights produced.\")\n",
    "\n",
    "# 5) Feature selection\n",
    "print(\"\\n🎯 Feature Selection Recommendation:\")\n",
    "if eda_state.get(\"feature_selection\"):\n",
    "    fs = eda_state[\"feature_selection\"]\n",
    "    print(\"Use all columns:\", fs.use_all_columns)\n",
    "    if not fs.use_all_columns:\n",
    "        print(\"Selected columns (suggested):\", fs.selected_columns)\n",
    "    print(\"Reason:\\n\", fs.reason)\n",
    "else:\n",
    "    print(\"No feature selection produced.\")\n",
    "\n",
    "# 6) Updated dataframe preview after imputations/encodings\n",
    "print(\"\\n📊 Updated DataFrame preview:\")\n",
    "updated_df = eda_state.get(\"df\", df)\n",
    "display(updated_df.head())\n",
    "print(\"Shape:\", updated_df.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
